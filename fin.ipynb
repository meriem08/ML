{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet:Customer Churn (Article 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : Exploration de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de forme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Telco_customer_churn.csv.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a269610be477>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Telco_customer_churn.csv.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m                 )\n\u001b[0;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Telco_customer_churn.csv.xlsx'"
     ]
    }
   ],
   "source": [
    "data=pd.read_excel('Telco_customer_churn.csv.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Dimension de la base de donnée Telco_Customer_Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Les dimensions de la bade de données sont : \" )\n",
    "print(\" * Nonmbre de lignes est :\", df.shape[0] )\n",
    "print(\" * Nonmbre de colonnes est :\", df.shape[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-Types de variables dans la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n",
    "df.dtypes.value_counts()\n",
    "#Notre base de données comporte des variables quantitative et qualitative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Valeurs nuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(df.isna(), cbar=False)\n",
    "#affficher les données manquantes (ou il y a du blanc on a des données manquantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isna().sum()/df.shape[0]).sort_values(ascending=True)#pourcentages des valeurs nulles ordonées\n",
    "# On verifie l'existance des valeurs nulles\n",
    "#En effet la variable Churn reseason contient 5174 Valeur nuls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probleme de la colonne Totals Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=len(df[df['Total Charges'] == \" \"])#on voit pas ce probleme avec sum() car Total charges est type object \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Total Charges'] == \" \"].index, inplace=True)#suppression des cases vides \n",
    "df['Total Charges'] = df['Total Charges'].astype('float64')#conversion de Total charges \n",
    "#en float car il etait initallement de type object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-unicité des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype=='O':\n",
    "        print(col)\n",
    "        print(df[col].unique())\n",
    "        \n",
    "### Verifier l'unicité des contenus des variables de types Objet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque :\n",
    "La base de données contient des colonnes non informatives par rapport au phenomene de desabonnement telques:\n",
    "CustomerID, Count(toutes les valeurs sont à 1), Country(Tous USA), State(Tous California),zip Code ,Lat Long ,Latitude, Longitude , Churn Label (Equivalante à Churn Value),Churn Reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de fond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visulation initiale - Elimination des colonnes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['CustomerID', 'Count', 'Country','State', \n",
    "              'Zip Code', 'Lat Long','Churn Label', 'Churn Reason', \n",
    "              'Lat Long', 'Latitude', 'Longitude','City','CLTV','Churn Score'], axis=1)\n",
    "#Suppression des colonnes non informatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in df.select_dtypes('object'):\n",
    "  #  a=len(df[df[col] == \" \"])\n",
    "   # print(a)\n",
    "#on a plus de valeurs nulles\n",
    "#for col in df.select_dtypes('int64'):\n",
    "  #  a=len(df[df[col] == \" \"])\n",
    "   # print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing[missing > 0].count()\n",
    "#on a plus de colonnes avec des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les colonnes qui restent sont:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Examen de la colonne target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on va appeler les clinets qui ont quitter le dernier mois Churning Customers et autres Non-Churning Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn Value'].value_counts(normalize=True)*100#nomalizepour afficher les resultats en pourcentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Churn Value\")\n",
    "plt.title('Churn Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seulement 26.5% des clients ont quitter le dernier mois donc une une base de données non equilibrée.Donc on devrait \n",
    "choisir une  une bonne métrique ,Accuracy dans ce cas n'est plus adaptée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Histogrames des valeurs quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('int64'):\n",
    "    plt.figure()\n",
    "    sns.distplot(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('float'):\n",
    "    plt.figure()\n",
    "    sns.distplot(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-variables qualitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('object'):\n",
    "    print(f'{col :-<50} {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('object'):\n",
    "    plt.figure()\n",
    "    df[col].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Relation Target/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a- Variables quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['Tenure Months', 'Monthly Charges', 'Total Charges']\n",
    "fig, ax = plt.subplots(figsize=(15, 9))\n",
    "ax = [plt.subplot(221), plt.subplot(222), plt.subplot(223)]\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "for i in range(0, len(ax)):\n",
    "    ax[i].set_title(\"Distribution of \" + num_features[i] + \" by Churn\")\n",
    "    ax[i].set_ylabel('Density')\n",
    "    ax[i].set_xlabel(num_features[i])\n",
    "    sns.kdeplot(df[df['Churn Value'] == 1][num_features[i]], color= 'red', label= 'Churn Value: 1', ax=ax[i])\n",
    "    sns.kdeplot(df[df['Churn Value'] == 0][num_features[i]], color= 'blue', label= 'Churn Value: 0', ax=ax[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATIONS:                                                                                     \n",
    "                  -  La plus part des Churners ont quitter des les premiers mois de Contract.                                \n",
    "                   - Il y a des gens qui restent dans cette entreprise depuis environ 70 mois. Mais les clients qui ont enregistré des services auprès de l'entreprise entre 1 et 8 ans sont susceptibles de quitter l'entreprise et de mettre fin aux services.\n",
    "-Le taux de churn augmente lorsque Monthly charges augmente.\n",
    "                            \n",
    " -La distribution de Total Chages est le resultat des deux autres distributions(Total Charges = Monthly Charges * Tenure Months) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b- Varaibles qalitatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fonction qui calcul le taux de churn pour chaque categories\n",
    "def plotFeature(feature, xoffset, yoffset):\n",
    "    df1 = df.groupby(feature)[\"Churn Value\"].value_counts().to_frame()\n",
    "    df1 = df1.rename({\"Churn Value\": \"Count\"}, axis=1).reset_index()\n",
    "    df1[\"Percentage\"] = df1[\"Count\"]/len(df)*100\n",
    "    \n",
    "    ax = sns.barplot(x=feature, y=\"Percentage\", hue=\"Churn Value\", data=df1)\n",
    "    ax.set_title(\"Churn percentages for each \" + feature)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width()/2 - xoffset,\n",
    "                height - yoffset,\n",
    "                '{:1.1f}%'.format(height),\n",
    "                weight='bold', color='white', size = 12) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GENDER - SENIORCITIZEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "plt.subplot(121)\n",
    "plotFeature(\"Gender\", 0.12, 4.5)\n",
    "plt.subplot(122)\n",
    "plotFeature(\"Senior Citizen\", 0.11, 4.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATIONS:                \n",
    "-La distribution de Gender est homogéne donc elle n'a pas de relation avec le Churn\n",
    "\n",
    "-on remarque aussi que lorsque Senir Citzen=No :leur taux de churn est superieur a cuex qui ont Senior Citizen=Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARTNER-DEPENDENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "plt.subplot(121)\n",
    "plotFeature(\"Partner\", 0.12, 4)\n",
    "plt.subplot(122)\n",
    "plotFeature(\"Dependents\", 0.12, 3.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATIONS:    \n",
    "     -on remaque ceux qui n'ont pas de partenaires leur taux de Churn est superieur a ceux qui ont un partenaire                  \n",
    "                           -les clients qui n'ont pas de dependaces ont un taux de churn superieur "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PHONE, INTERNET SERVICE, MULTIPLE LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,5))\n",
    "plt.subplot(131)\n",
    "plotFeature(\"Phone Service\", 0.12, 3)\n",
    "plt.subplot(132)\n",
    "plotFeature(\"Internet Service\", 0.18, 2)\n",
    "plt.subplot(133)\n",
    "plotFeature(\"Multiple Lines\", 0.18, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATIONS     \n",
    "         -les clients qui n'ont pas d'internet on a un taux de Churn inferieur a ceux qui ont acces a internet et les clients qui possedent des fibres\n",
    "optiques ont le taux de churn le plus élevé\n",
    "\n",
    "-Multiple Lines n'a pas vraiment d'influence\n",
    "\n",
    "-les clients qui possedent un Phone sevcice leur taux de Churn est superieur aux autres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONLINE SECURITY, ONLINE BACKUP, DEVICE PROTECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,5))\n",
    "plt.subplot(131)\n",
    "plotFeature(\"Online Security\", 0.18, 2)\n",
    "plt.subplot(132)\n",
    "plotFeature(\"Online Backup\", 0.18, 2)\n",
    "plt.subplot(133)\n",
    "plotFeature(\"Device Protection\", 0.18, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATIONS:      \n",
    "clients qui ne disposent pas de ces 3 services (Online Security, Online Backup and Device Protection) a quitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TECH SUPPORT, STREAMING TV, STREAMING MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,5))\n",
    "plt.subplot(131)\n",
    "plotFeature(\"Tech Support\", 0.18, 1.5)\n",
    "plt.subplot(132)\n",
    "plotFeature(\"Streaming TV\", 0.18, 1.5)\n",
    "plt.subplot(133)\n",
    "plotFeature(\"Streaming Movies\", 0.18, 1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATIONS:                                                                     \n",
    "-Les clients qui ne disposent pas d'un support technique sont plus susceptibles a quitter\n",
    "      \n",
    "-Le service de streaming Tv ou MOVIES n'est pas prédictif du désabonnement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONTRACT - PAPERLESS BILLING - PAYMENT METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.subplot(221)\n",
    "plotFeature(\"Contract\", 0.16, 1.5)\n",
    "plt.subplot(222)\n",
    "plotFeature(\"Paperless Billing\", 0.1, 2)\n",
    "plt.subplot(223)\n",
    "plotFeature(\"Payment Method\", 0.18, 1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERAVTAIONS:\n",
    "\n",
    "-Les contrats intuitivement à court terme ont un taux de désabonnement beaucoup plus élevé (Contract)\n",
    "\n",
    "-Les clients avec facturation sans papier ont un taux de désabonnement élevé(Paperless Billing)\n",
    "\n",
    "-La méthode de paiement du chèque électronique montre un taux de désabonnement beaucoup plus élevé que les autres(Payment Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-les valeurs extremes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les variables ne suivent pas une distribution normale donc on peut utiliser la  Methode IQR pour trouver les valerus aberantes (outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_features:\n",
    "    #calculer les quartiles\n",
    "    Q1 = df[i].quantile(0.25)\n",
    "    Q3 = df[i].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    #calculer les limites des valeurs aberantes\n",
    "    lower_limit = Q1 - 1.5*IQR\n",
    "    upper_limit = Q3 + 1.5*IQR\n",
    "    #identifier ces valeurs\n",
    "    print(((df[i] < lower_limit) | (df[i] > upper_limit)).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utlisant la methode IQR on n'a pas de valeurs aberantes numerique detectés "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Encodage des donnés qualitatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation d'un indicateur pour la variable gender en ululisant juste une colonne\n",
    "df = pd.get_dummies(df, columns=['Gender'], drop_first=True)\n",
    "\n",
    "# pour ces variables en va transformer les \"yes\" et \"no \"en 0 et 1\n",
    "vars1 = ['Partner', 'Dependents', 'Phone Service', 'Paperless Billing','Senior Citizen']\n",
    "map1 = {'No': 0, 'Yes': 1}\n",
    "for i in vars1:\n",
    "    df[i] = df[i].map(map1).astype('int')\n",
    "    \n",
    "#pour les variables ci_dessus on va utliser l'encodage one-hot puisque on a plus de deux categories dans chaque variables \n",
    "vars2 = ['Multiple Lines', 'Internet Service', 'Online Security', 'Online Backup', 'Device Protection', 'Tech Support',\n",
    "         'Streaming TV', 'Streaming Movies', 'Contract', 'Payment Method']\n",
    "df = pd.get_dummies(df, columns=vars2)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#les variavbles sont: tenure monthes, Monthly Charges and Total Charges\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[num_features] = scaler.fit_transform(df[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-correlation entre les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_for_target(data, target, title=None):\n",
    "    plt.figure(figsize=(4,14))\n",
    "    sns.set(font_scale=1)\n",
    "    \n",
    "    sns.heatmap(data.corr()[[target]].sort_values(target, ascending=False)[1:], annot=True, cmap=\"coolwarm\")\n",
    "    \n",
    "    if title: plt.title(f\"\\n{title}\\n\", fontsize=18)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_for_target(df, 'Churn Value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "on remarque ci-dessus  monthly contracts et l'absence de certains services\n",
    "(online security, techsupport) sont corrolés positivement avec churn Value par contre\n",
    " tenure months ,  contract_two year et l'absence du service internet sont corrolés negativement avec churn Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Churn Value\"], axis=1)\n",
    "y = df[\"Churn Value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insialisaton d'un dataframe qui garde la trace des modeles\n",
    "all_scores = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-les fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cette fonction prend le modèle, les caractéristiques et les valeurs cibles réelles, fait des prédictions,\n",
    "#puis imprime différents scores métriques\n",
    "def model_predictions(name, model, X, y, title):\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y, y_pred, average='binary')\n",
    "    scores = pd.DataFrame(columns=['Accuracy','Precision','Recall','F1'])\n",
    "    scores.loc[name] = [accuracy, precision, recall, f1]\n",
    "    print('----------------------------------------')\n",
    "    print(title)\n",
    "    print(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction trace la matrice de confusion avec / sans normalisation + courbe ROC \n",
    "def model_plots(model, X, y, title):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle(title, fontsize=18)\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    axes[0,0].set_title('Confusion Matrix')\n",
    "    plot_confusion_matrix(model, X, y, display_labels=['No Churn','Churn'], ax=axes[0,0])\n",
    "    axes[0,1].set_title('Normalized Confusion Matrix')\n",
    "    plot_confusion_matrix(model, X, y, normalize='true', display_labels=['No Churn','Churn'], ax=axes[0,1])\n",
    "    axes[1,0].set_title('ROC Curve')\n",
    "    plot_roc_curve(model, X, y, name='Log.Reg.', ax=axes[1,0])\n",
    "    #axes[1,1].set_title('Precision-Recall Curve')\n",
    "    #plot_precision_recall_curve(model, X, y, name='Log.Reg.', ax=axes[1,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction prend le modèle et ses paramètres associés en entrée et renvoie les meilleurs paramètres\n",
    "# à partir d'un ensemble donné à l'aide de l'algorithme de GridSearchCV (réglage des hyperparamètres)\n",
    "def hyperparam_gridcv(name, model, params):\n",
    "    gsearch = GridSearchCV(estimator=model, \n",
    "                           param_grid=params, \n",
    "                           scoring='f1',\n",
    "                           cv=5,\n",
    "                           n_jobs = -1)\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    print(name, \" - Best Parameters: \", gsearch.best_params_)\n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction prend le modèle et ses paramètres associés en entrée et renvoie les meilleurs paramètres\n",
    "# à partir d'un ensemble donné à l'aide de l'algorithme de recherche aléatoire\n",
    "def hyperparam_randcv(name, model, params):\n",
    "    gsearch = RandomizedSearchCV(estimator=model, \n",
    "                                 param_distributions=params, \n",
    "                                 n_iter = 100,\n",
    "                                 scoring='f1',\n",
    "                                 cv=5,\n",
    "                                 n_jobs = -1)\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    print(name, \" - Best Parameters: \", gsearch.best_params_)\n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a-la regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster le modèle de base\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=10)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenez les résultats du train et du test\n",
    "model_predictions('LOGREG', logreg, X_train, y_train, 'Logistic Reg. Training Set Scores')\n",
    "model_predictions('LOGREG', logreg, X_test, y_test, 'Logistic Reg. Test Set Scores')\n",
    "# Tracer la matrice de confusion, courbe ROC\n",
    "model_plots(logreg, X_test, y_test, \"Logistic Regression Results (Base Model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réglage des hyperparamètres (il est commenté car cela prend du temps)\n",
    "params_logreg = {'penalty':['l1','l2'], 'C':np.arange(0.1, 3, 0.1)}\n",
    "#hyperparam_gridcv('Logistic Regression', logreg, params_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, C=1.1, penalty='l2', random_state=10)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "logreg_results = model_predictions('LOGREG', logreg, X_test, y_test, 'Logistic Reg. Test Set Scores')\n",
    "all_scores = all_scores.append(logreg_results)\n",
    "\n",
    "model_plots(logreg, X_test, y_test, \"Logistic Regression Results (Tuned Model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster le modèle de base\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenez les résultats du train et du test\n",
    "\n",
    "model_predictions('KNN', knn, X_train, y_train, 'KNN Training Set Scores')\n",
    "model_predictions('KNN', knn, X_test, y_test, 'KNN Test Set Scores')\n",
    "# Tracer la matrice de confusion, courbe ROC\n",
    "model_plots(knn, X_test, y_test, \"KNN Results (Base Model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réglage des hyperparamètres\n",
    "params_knn = {'n_neighbors':np.arange(3, 25, 1), \n",
    "              'metric':['euclidean','manhattan','minkowski']}\n",
    "#hyperparam_gridcv('K-Nearest Neighbors', knn, params_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=19, metric='manhattan')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_results = model_predictions('KNN', knn, X_test, y_test, 'KNN Test Set Scores')\n",
    "all_scores = all_scores.append(knn_results)\n",
    "\n",
    "model_plots(knn, X_test, y_test, \"KNN Results (Tuned Model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c-Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster le modèle de base\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenez les résultats du train et du test\n",
    "\n",
    "model_predictions('RND.FOR.', rf, X_train, y_train, 'Random Forest Training Set Scores')\n",
    "model_predictions('RND.FOR.', rf, X_test, y_test, 'Random Forest Test Set Scores')\n",
    "# Tracer la matrice de confusion, courbe ROC\n",
    "model_plots(rf, X_test, y_test, \"Random Forest Results (Base Model)\")\n",
    " #0.794653   0.591379  0.734475  0.655205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réglage des hyperparamètres\n",
    "params_rf = {'n_estimators':[100, 500, 1000, 1500],\n",
    "             'max_depth':np.append(np.arange(10, 60, 10), None),\n",
    "             'class_weight':[None, 'balanced', 'balanced_subsample'],\n",
    "             'min_samples_split': [2, 5, 10],\n",
    "             'min_samples_leaf': [1, 2, 5]\n",
    "            }\n",
    "\n",
    "#hyperparam_gridcv('Random Forest', rf, params_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "                            max_depth=10, \n",
    "                            max_features='auto', \n",
    "                            min_samples_split=5,\n",
    "                            min_samples_leaf=2, \n",
    "                            class_weight='balanced_subsample',\n",
    "                            random_state=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_results = model_predictions('RND.FOR.', rf, X_test, y_test, 'Random Forest Test Set Scores')\n",
    "all_scores = all_scores.append(rf_results)\n",
    "\n",
    "model_plots(rf, X_test, y_test, \"Random Forest Results (Tuned Model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l'importance des paramétres\n",
    "features = pd.DataFrame()\n",
    "features['feature'] = X.columns\n",
    "features['importance'] = rf.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features.set_index('feature', inplace=True)\n",
    "\n",
    "features.plot(kind='barh', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATIONS\n",
    "\n",
    "le modele ajusté a une perfomance legemerment superieur aux deux premiers algorithmes\n",
    "les premiers alogorithmes peuvent predire que 50% des clients qui vont quitter parcontre le random Forest peut predire jusqu'a 75% des churners.\n",
    "\n",
    "D'apres features Importance Tenure monthes,total charges, contact month_to_month and monthly charges sont les variables les plus importantes dans la prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d-SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster le modèle de base\n",
    "svm = SVC(random_state=10)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenez les résultats du train et du test\n",
    "model_predictions('SVM', svm, X_train, y_train, 'SVM Training Set Scores')\n",
    "model_predictions('SVM', svm, X_test, y_test, 'SVM Test Set Scores')\n",
    "# Tracer la matrice de confusion, courbe ROC\n",
    "model_plots(svm, X_test, y_test, \"SVM Results (Base Model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réglage des hyperparamètres\n",
    "params_svm = {'C':np.arange(0.1, 3, 0.1), 'kernel':['linear', 'poly', 'rbf']}\n",
    "#hyperparam_gridcv('SVM', svm, params_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=0.3,\n",
    "          kernel='linear',\n",
    "          random_state=10)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_results = model_predictions('SVM', svm, X_test, y_test, 'SVM Test Set Scores')\n",
    "all_scores = all_scores.append(svm_results)\n",
    "\n",
    "model_plots(svm, X_test, y_test, \"SVM Results (Tuned Model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATION\n",
    "\n",
    "Le modèle ajusté a des résultats légèrement meilleurs que le modèle de base, mais dans l'ensemble, \n",
    "il est médiocre pour prédire le taux de désabonnement des clients comme la régression logistique et le modèle KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f-XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster le modèle de base\n",
    "xgb = XGBClassifier(random_state=10)\n",
    "#xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenez les résultats du train et du test\n",
    "model_predictions('XGB', xgb, X_train, y_train, 'XGB Training Set Scores')\n",
    "model_predictions('XGB', xgb, X_test, y_test, 'XGB Test Set Scores')\n",
    "# Tracer la matrice de confusion, courbe ROC\n",
    "model_plots(xgb, X_test, y_test, \"XGB Results (Base Model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-395918eed65e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m               \u001b[1;34m'gamma'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m               'scale_pos_weight':[1,2,3]}\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mhyperparam_randcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'XGB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_xgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-8c4f5f3c4728>\u001b[0m in \u001b[0;36mhyperparam_randcv\u001b[1;34m(name, model, params)\u001b[0m\n\u001b[0;32m      8\u001b[0m                                  \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                  n_jobs = -1)\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mgsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" - Best Parameters: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Réglage des hyperparamètres\n",
    "params_xgb = {'learning_rate': [0.01, 0.05, 0.1],\n",
    "              'max_depth': [3, 5, 7, 10], \n",
    "              'min_child_weight': [1, 5, 10],\n",
    "              'subsample': [0.5, 0.7, 0.9],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'gamma': [0, 0.05, 0.1],\n",
    "              'scale_pos_weight':[1,2,3]}\n",
    "#hyperparam_randcv('XGB', xgb, params_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=100,\n",
    "                    learning_rate=0.05,\n",
    "                    max_depth=3,\n",
    "                    min_child_weight=10,\n",
    "                    subsample=0.5,\n",
    "                    colsample_bytree=0.8,\n",
    "                    gamma=0.05,\n",
    "                    scale_pos_weight=2,\n",
    "                    random_state=10)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb_results = model_predictions('XGB', xgb, X_test, y_test, 'XGB Test Set Scores')\n",
    "all_scores = all_scores.append(xgb_results)\n",
    "\n",
    "model_plots(xgb, X_test, y_test, \"XGB Results (Tuned Model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e-LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster le modèle de base\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenez les résultats du train et du test\n",
    "model_predictions('LGBM', lgbm, X_train, y_train, 'LGBM Training Set Scores')\n",
    "model_predictions('LGBM', lgbm, X_test, y_test, 'LGBM Test Set Scores')\n",
    "# Tracer la matrice de confusion, courbe ROC\n",
    "model_plots(lgbm, X_test, y_test, \"LGBM Results (Base Model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réglage des hyperparamètres\n",
    "params_lgbm = {'learning_rate': [0.01, 0.05, 0.1],\n",
    "               'n_estimators' : [100, 1000, 2000],\n",
    "               'max_depth': [-1, 3, 5, 7],\n",
    "               'min_child_weight': [1, 10, 100],\n",
    "               'subsample': [0.5, 0.7, 0.9],\n",
    "               'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "               'reg_alpha': [0, 1, 5, 10],\n",
    "               'scale_pos_weight':[1, 1.5, 2]}\n",
    "#hyperparam_randcv('LGBM', lgbm, params_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(n_estimators=2000,\n",
    "                    learning_rate=0.1,\n",
    "                    min_child_weight=100,\n",
    "                    max_depth=3,\n",
    "                    subsample=0.5,\n",
    "                    colsample_bytree=1,\n",
    "                    scale_pos_weight=2,\n",
    "                    reg_alpha=10,\n",
    "                    random_state=10)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "lgbm_results = model_predictions('LGBM', lgbm, X_test, y_test, 'LGBM Test Set Scores')\n",
    "all_scores = all_scores.append(lgbm_results)\n",
    "\n",
    "model_plots(lgbm, X_test, y_test, \"LGBM Results (Tuned Model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_scores.sort_values(by='F1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultinomialNB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele pour les trois type d'algorithme de Naive Bayes:\n",
    "nb={'gaussian':GaussianNB(),'Bernoulli':BernoulliNB(),'Multinomial': MultinomialNB()}\n",
    "score={}\n",
    "for key,model in nb.items():\n",
    "    s=cross_val_score(model,X_train,y_train,cv=5, scoring='accuracy')\n",
    "    score[key]=np.mean(s)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveMulti= MultinomialNB()\n",
    "NaiveMulti.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les prédictions\n",
    "y_pred=NaiveMulti.predict(X_test)\n",
    "#évaluation de notre modèle\n",
    "print (\"précision: \", accuracy_score(y_test, y_pred))\n",
    "print (\"test score: \", NaiveMulti.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveMulti_results=model_predictions('NaiveMulti', NaiveMulti, X_test, y_test, 'NaiveMulti. Test Set Scores')\n",
    "model_plots(NaiveMulti, X_test, y_test, \"NaiveMulti  Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = all_scores.append(NaiveMulti_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sbfs = SFS(model, \n",
    "          k_features=1, \n",
    "           forward=False, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5,\n",
    "           n_jobs=-1)\n",
    "\n",
    "sbfs = sbfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(sbfs.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSFS 1 :')\n",
    "print(sbfs.k_feature_idx_)\n",
    "print('CV Score:')\n",
    "print(sbfs.k_score_)\n",
    "print('CV Score:')\n",
    "print(sbfs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbfs = SFS(model, \n",
    "          k_features=2, \n",
    "           forward=False, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5,\n",
    "           n_jobs=-1)\n",
    "\n",
    "sbfs = sbfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(sbfs.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSFS 2 :')\n",
    "print(sbfs.k_feature_idx_)\n",
    "print('CV Score:')\n",
    "print(sbfs.k_score_)\n",
    "print('CV Score:')\n",
    "print(sbfs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbfs = SFS(model, \n",
    "          k_features=3, \n",
    "           forward=False, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5,\n",
    "           n_jobs=-1)\n",
    "\n",
    "sbfs = sbfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(sbfs.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSFS 3 :')\n",
    "print(sbfs.k_feature_idx_)\n",
    "print('CV Score:')\n",
    "print(sbfs.k_score_)\n",
    "print('CV Score:')\n",
    "print(sbfs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbfs = SFS(model, \n",
    "          k_features=4, \n",
    "           forward=False, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5,\n",
    "           n_jobs=-1)\n",
    "\n",
    "sbfs = sbfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSFS 4 :')\n",
    "print(sbfs.k_feature_idx_)\n",
    "print('CV Score:')\n",
    "print(sbfs.k_score_)\n",
    "print('CV Score:')\n",
    "print(sbfs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)# modèle d' apprentissage automatique se généralise à des données similaires à celles sur lesquelles i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, X_test, y_test,cmap=plt.cm.Blues)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nb2=X_train[['Dependents','Tenure Months', 'Internet Service_Fiber optic', 'Contract_Month-to-month']].copy()\n",
    "X_test_nb2=X_test[['Dependents','Tenure Months', 'Internet Service_Fiber optic', 'Contract_Month-to-month']].copy()\n",
    "\n",
    "model2=GaussianNB()\n",
    "model2 = model2.fit(X_train_nb2, y_train)\n",
    "\n",
    "print('train score ')\n",
    "print('Befor', model.score(X_test,y_test),'  After:', model2.score(X_train_nb2,y_train))\n",
    "print('test score ')\n",
    "print('Befor :', model.score(X_test,y_test),'  After: ',model2.score(X_test_nb2,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.sort_values(by='F1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le meuilleur algorithme est light GBM car il a le meuilleur score F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
